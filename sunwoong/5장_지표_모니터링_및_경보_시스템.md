잘 설계된 지표 모니터링 및 경보 시스템은 인프라의 상태를 선명하게 볼 수 있도록 하여 높은 가용성과 안정성을 달성하는 데 중추적 역할을 한다.

### 1단계. 문제 이해 및 설계 범위 확정

---

**개략적 요구사항 및 가정**

- 대규모 인프라 모니터링
    - DAU 1억명
    - 서버 풀 1000개, 풀당 서버 수 100개, 서버당 100개의 운영 지표를 수집. 대략 1000만개 지표 수
    - 데이터 보관 기간 1년
    - 수집한 그대로 데이터를 보관하는 기간은 일주일. 이후 1분 단위 데이터로 변환 후 30일 보관. 이후 1시간 단위 데이터로 변환 후 1년 보관
- 모니터링 지표
    - CPU 사용률
    - 요청 수
    - 메모리 사용량
    - 메시지 큐 내의 메시지 수

**비기능 요구사항**

- 규모 확장성
- 낮은 응답 지연
- 안정성
- 유연성
- 로그 모니터링 또는 분산 시스템 추적은 고려하지 않음

### 2단계. 개략적 설계안 제시 및 동의 구하기

---

**기본적 사항**

- 데이터 수집
    - 여러 출처로부터 지표 데이터 수집
- 데이터 전송
    - 지표 데이터를 지표 모니터링 시스템으로 전송
- 데이터 저장소
    - 전송되어 오는 데이터를 정리하고 저장
- 경보
    - 밀려오는 데이터 분석, 이상 징후 감지 및 경보 발생
    - 다양한 통신 채널로 경보 발송
- 시각화
    - 데이터를 차트나 그래프 등으로 제공

**데이터 모델**

지표 데이터는 통상 시계열 데이터 형태로 기록. 값 집합에 타임스탬프가 붙은 형태로 기록한다는 뜻.

| 이름 | 자료형 |
| --- | --- |
| 지표 이름 | 문자열 |
| 태그/레이블 집합 | <키:값> 쌍의 리스트 |
| 지표 값 및 그 타임스탬프의 배열 | <값, 타임스탬프> 쌍의 배열 |

**데이터 접근 패턴**

y축에 붙은 레이블은 하나의 시계열 데이터를 나타내고 x축에 붙은 레이블은 시간이다.

이 시스템에 대한 쓰기 부하는 막대하다. 매일 천만 개 운영 지표가 기록되며 상당수의 지표는 발생 빈도도 높다. 따라서 이 시스템으로 오는 트래픽은 쓰기가 압도적이다.

읽기 부하는 일시적으로 치솟았다 사라지는 편이라고 봐야 한다. 시각화와 경보 서비스는 데이터베이스에 대한 읽기 연산을 발생시킨다. 따라서 그래프나 경보를 확인하는 패턴에 따라 읽기 연산은 일시적으로 증가하였다가 잠잠해질 수 있다.

이 시스템은 많은 양의 쓰기 연산 부하를 감당해야 하지만 읽기 연산의 부하는 잠시 급증하였다가 곧 사라지곤 한다는 것이다.

**데이터 저장소 시스템**

데이터 저장소 시스템은 본 설계안의 핵심이다. 지표 모니터링 및 경보 시스템을 위한 저장소 시스템을 직접 설계하거나, MySQL 같은 범용의 저장소 시스템을 사용하는 선택지 가운데 어떤 것도 추천하지 않는다.

범용 데이터베이스는 이론적으로는 시계열 데이터를 처리할 수 있지만 이 설계안이 감당하려는 부하 규모에 맞추려면 전문가 수준의 튜닝이 필요하다.

NoSQL에서 시계열 데이터를 효과적으로 저장하고 질의하기 위해서는 확장이 용이한 스키마를 설계해야 하는데, 그러려면 해당 NoSQL 데이터베이스의 내부 구조에 대한 해박한 지식이 필요하다.

기업에 필요한 규모를 지원하는 시계열 데이터베이스가 시장에 나와 있는 만큼 범용 NoSQL 데이터베이스를 사용하는 방안은 그다지 매력적이지 않다.

DB-engines에서 조사한 결과에 따르면, 시장에서 가장 인기 있는 시계열 데이터베이스 두 가지는 InfluxDB, Prometheus이다. 다량의 시계열 데이터를 저장하고 빠른 실시간 분석을 지원하는 것이 특징이다. 두 제품 모두 메모리 캐시와 디스크 저장소를 함께 사용한다. 영속성 요건과 높은 성능 요구사항도 잘 만족한다.

중요한 것은 지표 데이터는 본질적으로 시계열 데이터이므로 InfluxDB 같은 시계열 데이터베이스에 저장할 수 있음을 설명하는 것이다.

**개략적 설계안**

- 지표 출처: 지표 데이터가 만들어지는 곳으로 애플리케이션 서버, SQL 데이터베이스, 메시지 큐 등 어떤 것이든 가능
- 지표 수집기: 지표 데이터를 수집하고 시계열 데이터에 기록하는 역할
- 시계열 데이터베이스: 지표 데이터를 시계열 데이터 형태로 보관하는 저장소다. 다량의 시계열 데이터를 분석하고 요약하는데 적합하도록 설계된 질의 인터페이스를 제공
- 질의 서비스: 시계열 데이터베이스에 보관된 데이터를 질의하고 가져오는 과정을 돕는 서비스
- 경보 시스템: 경보를 받아야 하는 다양한 대상으로 경보 알림을 전송하는 역할
- 시각화 시스템: 지표를 다양한 형태의 그래프/차트로 시각화 하는 기능을 제공하는 시스템

### 3단계. 상세 설계

---

### **지표 수집**

---

카운터나 CPU 사용량 같은 지표를 수집할 때는 때로 데이터가 소실되어도 아주 심각한 문제는 아니다. 즉, 지표를 보내는 클라이언트는 성공적으로 데이터가 전송되었는지 신경 쓰기 않아도 상관없다.

**풀 모델**

실행 중인 애플리케이션에서 주기적으로 지표 데이터를 가져오는 지표 수집기가 이 흐름의 중심이다. 지표 수집기는 데이터를 가져올 서비스 목록을 알고 있어야 한다. 지표 수집기 서버 안에 모든 서비스 엔드포인트의 DNS/IP 정보를 담은 파일을 두면 가장 간단하다.

하지만 서버가 수시로 추가/삭제되는 대규모 운영 환경에는 적용하기 어렵다. 그러나, etcd나 아파치 주키퍼 같은 서비스 탐색 기술을 활용하면 이 문제는 해결할 수 있다. 즉, 각 서비스는 자신의 가용성 관련 정보를 서비스 탐색 서비스(SDS)에 기록하고 SDS는 서비스 엔드포인트 목록에 변화가 생길 때마다 지표 수집기에 통보하는 것이다. SDS에는 언제 어디서 지표를 수집하면 되는지에 관한 설정 정보를 기록한다.

1. 지표 수집기는 SDS에서 서비스 엔드포인트 설정 메타데이터 목록을 가져온다. 각 메타데이터에는 지표 수집 주기, IP 주소, 타임아웃, 재시도 인자 등이 기록되어 있다.
2. 지표 수집기는 사전에 합의된 HTTP 엔드포인트에서 지표 데이터를 가져온다.
3. 지표 수집기는 서비스 엔드포인트 목록의 변화를 통지 받기 위한 변경 이벤트 알림 콜백을 서비스 탐색 컴포넌트에 등록할 수 있다. 대신 주기적으로 서비스 탐색 컴포넌트에서 엔드포인트 목록을 다시 가져와도 된다.

막대한 지표 데이터 규모를 감당하기 위해서는 지표 수집기 서버 풀을 만들어야 한다. 지표 수집기 서버를 여러 대 둘 때 흔히 빚어지는 문제는 여러 서버가 같은 출처에서 데이터를 중복해서 가져올 가능성이 있다는 것이다. 따라서 지표 수집 서버 간에 중개 메커니즘이 존재해야 한다.

안정 해시 링을 사용해서 중재 메커니즘을 구현할 수 있다. 즉, 해시 링 구간마다 해당 구간에 속한 서버로부터 생산되는 지표의 수집을 담당하는 수집기 서버를 지정하는 것이다. 이렇게 하면 특정 서버의 지표 데이터는 항상 하나의 수집 서버가 처리함을 보장할 수 있다.

**푸시 모델**

푸시 모델은 지표 출처에 해당하는 서버, 즉 웹 서버나 데이터베이스 서버 같은 서버가 직접 지표를 수집기에 전송하는 모델이다.

푸시 모델의 경우, 모니터링 대상 서버에 수집 에이전트라고 부르는 소프트웨어를 설치한다. 수집 에이전트는 해당 장비에서 실행되는 서비스가 생산하는 지표 데이터를 받아 모은 다음 주기적으로 수집기에 전달한다. 간단한 지표의 경우 에이전트가 직접 데이터 집계 등의 작업을 처리할 수도 있다. 데이터 집계는 수집기에 보내는 데이터의 양을 줄이는 효과적인 방법이다.

데이터 전송 트래픽의 양이 막대하여 수집기가 일시적으로 전송되는 데이터를 처리하지 못하게 되어 오류를 반환하면 에이전트는 내부적으로 소규모 버퍼에 데이터를 일시적으로 보관한 다음 나중에 재전송할 수도 있을 것이다. 하지만 에이전트가 위치한 서버 클러스터가 오토스케일링이 적용되어 있다면 동작 과정에서 데이터가 소실 될 수도 있다.

지표 수집기가 밀려드는 지표 데이터를 제때 처리하지 못하는 일을 방지하려면, 지표 수집기 클러스터 자체도 오토스케일링이 가능하도록 구성하고 로드밸런서를 두는 것이 바람직하다.

**풀 vs 푸시 모델 장단점**

프로메테우스 - 풀 모델

CloudWatch - 푸시 모델

풀

- 애플리케이션 서버에 /metrics 엔드포인트를 두도록 강제하므로 언제든지 지표 데이터를 볼 수 있어서 손쉬운 디버깅에 용이하다.
- 애플리케이션 서버가 풀 요청에 응답하지 않으면 장애 감지가 가능하다. 따라서 상태 진단에 용이하다.
- 모든 /metrics 엔드포인트가 접근 가능하도록 구성되어야 한다. 데이터센터를 여러 개 사용하는 경우에는 문제가 될 수 있으며 네트워크 인프라를 세심히 설계해야 한다.
- 풀 모델은 일반적으로 TCP를 사용한다. 따라서 푸시 모델에 비해 전송 지연이 더 높다.
- 지표 데이터를 가져올 애플리케이션 서버의 목록이 이미 정의된 상태이므로 해당 서버에서 수집한 데이터는 신뢰할 수 있다.

푸시

- 지표 수집기가 지표를 받지 못하면 원인 파악이 어렵다.
- 생명 주기가 짧은 일괄 작업 프로세스의 경우 수집기가 미처 지표를 끌어가기도 전에 종료되어 버릴 수 있다. 반면에 풀 모델은 푸시 게이트웨이를 도입하면 해당 문제점을 해결할 수 있다.
- 지표 수집기가 로드밸런서 및 오토스케일링 형태로 구성되었다면 어디서 오는 지표라도 수집 가능하다.
- 푸시 모델은 일반적으로 UDP를 사용한다. 풀 모델에 비해 전송 지연이 더 낮다.
- 아무나 지표 수집기에 데이터를 보낼 수 있다는 문제가 있다. 지표 전송을 허용할 서버의 목록을 수집기 측에 유지하거나 인증을 강제하면 문제를 해결할 수 있다.

### 지표 전송 파이프라인의 규모 확장

---

지표 수집기는 서버 클러스터 형태이며 막대 양의 데이터를 받아 처리해야 한다. 또한, 클러스터는 오토스케일링이 가능하도록 설정하여 언제나 데이터 처리에 충분한 수집기 서버가 존재하도록 해야 한다.

하지만 시계열 데이터베이스에 장애가 생기면 데이터 손실이 발생할 가능성이 있다. 큐를 두어 문제를 해결할 수 있는데, 본 설계안에서 지표 수집기는 지표 데이터를 카프카와 같은 큐 시스템에 전송한다.

소비자 즉, 스트림 처리 서비스가 해당 데이터를 받아 시계열 데이터베이스에 저장하며 이 구조는 다음과 같은 장점이 있다.

- 카프카는 안정적이고 규모 확장성이 뛰어난 분산 메시지 플랫폼
- 데이터 수집과 처리 컴포넌트 사이의 결합도 감소
- 데이터베이스 장애 시 데이터 손실 X → 카프카에 보관

**카프카를 통한 규모 확장**

카프카에 내장된 파티션 메커니즘을 사용하면 시스템의 규모를 다양한 방법으로 확장할 수 있음.

- 대역폭 요구사항에 따라 파티션 수 결정
- 지표 이름에 따라 어떤 지표를 어느 파티션에 배치할지 결정 → 소비자는 지표 이름에 따라 데이터를 집계
- 태그/레이블에 따라 지표 데이터 세분화
- 우선순위에 따른 지표 분류 및 처리

**카프카의 대안**

- 상용 규모의 카프카 시스템 구축은 쉽지 않다.
- 큐 없이도 대규모 데이터 처리가 가능한 모니터링 시스템 존재
    - ex) 페이스북의 메모리 기반 시계열 데이터베이스 고릴라(Gorilla)

### **데이터 집계 시점**

---

지표 집계는 다양한 지점에서 실행 가능하다.

**수집 에이전트 집계**

클라이언트에 설치된 수집 에이전트는 복잡한 집계 로직은 지원하기 어렵다.

**데이터 수집 파이프라인 집계**

데이터를 저장소에 기록하기 전에 집계할 수 있으려면 스트림 프로세싱 엔진이 필요하다. 데이터베이스에는 계산 결과만 기록하므로 실제로 기록되는 양은 매우 감소할 것이다.

하지만 늦게 도착하는 지표 데이터의 처리가 어렵고, 원본 데이터를 보관하지 않기 때문에 정밀도나 유연성 측면에서 손해를 보게 된다는 문제가 존재한다.

**질의 시 집계**

데이터를 날 것 그대로 보관한 다음 질의할 때 필요한 시간 구간에 맞게 집계. 데이터 손실 문제는 없으나 질의 처리 순간에 전체 데이터세트를 대상으로 집계 결과를 계산해야 하므로 속도는 느릴 것.

### 저장소 계층

---

**시계열 데이터베이스는 신중하게 선택할 것**

페이스북 연구 논문에 따르면 운영 데이터 저장소에 대한 질의의 85%는 지난 26시간 내에 수집된 데이터가 대상이다.

이를 활용하여 시계열 데이터베이스를 선택하면 성능 측면에서 큰 이득을 볼 수 있다.

**저장 용량 최적화**

지표 모니터링 시스템에 저장할 데이터의 양은 막대하다. 이를 최적화하여 저장하는 것이 중요하다.

1. 데이터 인코딩 및 압축
    1. 1610087371, 1610087381은 10초만 다른 값이며 타임스탬프 하나를 표현하는데는 32비트가 필요하지만 10을 표현하는데는 4비트면 충분하다.
    2. 데이터를 완전히 표현하는 대신 1610087371, 10 처럼 값의 차이를 저장한다.
2. 다운샘플링
    1. 데이터의 해상도를 낮춰 저장소 요구량을 줄이는 기법
    2. 해상도 → 데이터가 어떤 단위로 수집되고 집계되었나?
3. 냉동저장소
    1. 잘 사용되지 않는 비활성 상태 데이터를 보관하는 곳
    2. 냉동 저장에 드는 비용은 일반 저장소에 비해 훨씬 낮다.